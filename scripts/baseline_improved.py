"""
æ”¹å–„ç‰ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆZennè¨˜äº‹å‚è€ƒï¼‰

å‚è€ƒ: https://zenn.dev/mmrbulbul/articles/signate-geospatial-challenge-2025-01-baseline

ä¸»ãªæ”¹å–„ç‚¹:
1. ã‚¹ãƒ©ãƒƒã‚·ãƒ¥åŒºåˆ‡ã‚Šç‰¹å¾´é‡ã®one-hotå±•é–‹
2. logå¤‰æ› + MAEæå¤±
3. æ—¥ä»˜ç‰¹å¾´é‡ã®å‡¦ç†
4. ä½æ‰€ç‰¹å¾´é‡ã®æŠ½å‡º
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from datetime import datetime
import warnings

from src.data.preprocess import preprocess_for_catboost
from src.models.train_catboost import train_catboost_cv, predict_with_models

warnings.filterwarnings('ignore')

# ãƒ‘ã‚¹è¨­å®š
TRAIN_PATH = "data/raw/train.csv"
TEST_PATH = "data/raw/test.csv"
SAMPLE_PATH = "data/raw/sample_submit.csv"
OUTPUT_DIR = "submissions/exp002_improved"

print("=" * 60)
print("æ”¹å–„ç‰ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ - CatBoost + ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
print("å‚è€ƒ: Zennè¨˜äº‹")
print("=" * 60)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
print("\n[1] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
train = pd.read_csv(TRAIN_PATH)
test = pd.read_csv(TEST_PATH)
sample_sub = pd.read_csv(SAMPLE_PATH, header=None, names=['id', 'money_room'])

print(f"Train shape: {train.shape}")
print(f"Test shape: {test.shape}")

# å‰å‡¦ç†
print("\n[2] å‰å‡¦ç†...")
train_features, test_features, target, cat_features = preprocess_for_catboost(
    train, test, target_col='money_room', apply_log=True
)

# ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
params = {
    'iterations': 2000,
    'learning_rate': 0.05,
    'depth': 6,
    'loss_function': 'MAE',  # logå¤‰æ›å¾Œã¯MAEãŒåŠ¹æœçš„
    'eval_metric': 'MAE',
    'random_seed': 42,
    'verbose': 100,
    'early_stopping_rounds': 50,
}

# Cross Validation
print("\n[3] Cross Validation...")
models, cv_scores = train_catboost_cv(
    train_features, target, cat_features,
    n_splits=5, params=params, verbose=100
)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
print("\n[4] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬...")
predictions = predict_with_models(
    models, test_features, cat_features, apply_expm1=True
)

# Submissionä½œæˆ
print("\n[5] Submissionä½œæˆ...")
submission = sample_sub.copy()
submission['money_room'] = predictions.astype(int)

# ä¿å­˜
os.makedirs(OUTPUT_DIR, exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_path = f"{OUTPUT_DIR}/submission_{timestamp}.csv"
submission.to_csv(output_path, index=False, header=False)

print(f"\n{'='*60}")
print(f"å®Œäº†!")
print(f"{'='*60}")
print(f"Submission saved to: {output_path}")
print(f"\näºˆæ¸¬å€¤ã®çµ±è¨ˆ:")
print(submission['money_room'].describe())
print(f"\nCV MAPE: {np.mean(cv_scores):.4f}% (+/- {np.std(cv_scores):.4f}%)")
print(f"{'='*60}")
print("Ready to submit! ğŸš€")
print(f"{'='*60}")

# ç‰¹å¾´é‡é‡è¦åº¦ã®ä¿å­˜
print("\n[6] ç‰¹å¾´é‡é‡è¦åº¦ã®ä¿å­˜...")
feature_importance = pd.DataFrame({
    'feature': train_features.columns,
    'importance': models[0].feature_importances_
}).sort_values('importance', ascending=False)

importance_path = f"{OUTPUT_DIR}/feature_importance_{timestamp}.csv"
feature_importance.to_csv(importance_path, index=False)
print(f"Feature importance saved to: {importance_path}")

print("\nTop 20 é‡è¦ãªç‰¹å¾´é‡:")
print(feature_importance.head(20).to_string(index=False))

