"""
Target Encodingã®åŠ¹æœã‚’åˆ†æï¼ˆå‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
trainã¨testã§ã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ©ãƒ ã®é‡è¤‡ç‡ã‚’ãƒã‚§ãƒƒã‚¯
"""
import pickle
from pathlib import Path

import pandas as pd

# ãƒ‘ã‚¹è¨­å®š
project_root = Path(__file__).resolve().parent.parent
processed_dir = project_root / "data" / "processed"

# å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
if not (processed_dir / "train_processed.parquet").exists():
    print("âŒ å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    print("å…ˆã« baseline_with_geo_features.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    exit(1)

print("å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
train = pd.read_parquet(processed_dir / "train_processed.parquet")
test = pd.read_parquet(processed_dir / "test_processed.parquet")

print(f"Train shape: {train.shape}")
print(f"Test shape: {test.shape}")

# Target Encodingå¯¾è±¡ã®ã‚«ãƒ©ãƒ 
te_columns = ["city", "prefecture", "eki_name1"]

# å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’ä½¿ç”¨
te_columns = [col for col in te_columns if col in train.columns]
print(f"\nå¯¾è±¡ã‚«ãƒ©ãƒ : {te_columns}")

print("\n" + "=" * 80)
print("Target Encoding ã‚«ãƒ©ãƒ ã®é‡è¤‡åˆ†æ")
print("=" * 80)

for col in te_columns:
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã®æ•°
    train_unique = set(train[col].dropna().unique())
    test_unique = set(test[col].dropna().unique())

    # é‡è¤‡
    overlap = train_unique & test_unique

    # testã«ã—ã‹å­˜åœ¨ã—ãªã„å€¤ï¼ˆtrainã§å­¦ç¿’ã§ããªã„ï¼‰
    test_only = test_unique - train_unique

    # trainã«ã—ã‹å­˜åœ¨ã—ãªã„å€¤
    train_only = train_unique - test_unique

    # ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ï¼ˆtestã®å€¤ã®ã†ã¡ã€trainã«ã‚‚å­˜åœ¨ã™ã‚‹å‰²åˆï¼‰
    coverage = len(overlap) / len(test_unique) * 100 if len(test_unique) > 0 else 0

    # testãƒ‡ãƒ¼ã‚¿ã§ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
    test_covered = test[test[col].isin(train_unique)]
    record_coverage = len(test_covered) / len(test) * 100

    print(f"\nğŸ“Š {col}:")
    print(f"  Train unique values: {len(train_unique):,}")
    print(f"  Test unique values:  {len(test_unique):,}")
    print(f"  Overlap:             {len(overlap):,}")
    print(f"  Test only:           {len(test_only):,}")
    print(f"  Train only:          {len(train_only):,}")
    print(f"  âœ… Coverage (å€¤):     {coverage:.2f}%")
    print(f"  âœ… Coverage (ãƒ¬ã‚³ãƒ¼ãƒ‰): {record_coverage:.2f}%")

    if len(test_only) > 0 and len(test_only) <= 20:
        print(f"  Test only values: {sorted(list(test_only))}")

    # Target Encodingã®åŠ¹æœäºˆæ¸¬
    if coverage >= 95 and record_coverage >= 95:
        print("  ğŸ’š TEãŒéå¸¸ã«åŠ¹æœçš„")
    elif coverage >= 80 and record_coverage >= 90:
        print("  ğŸ’› TEãŒåŠ¹æœçš„ï¼ˆä¸€éƒ¨æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã‚ã‚Šï¼‰")
    elif coverage >= 50:
        print("  ğŸŸ  TEã®åŠ¹æœã¯é™å®šçš„")
    else:
        print("  ğŸ”´ TEã¯ã‚ã¾ã‚ŠåŠ¹æœçš„ã§ãªã„å¯èƒ½æ€§")

# é »åº¦ã®åˆ†æ
print("\n" + "=" * 80)
print("ã‚«ãƒ†ã‚´ãƒªã®é »åº¦åˆ†å¸ƒï¼ˆTop 10ï¼‰")
print("=" * 80)

for col in te_columns:
    print(f"\nğŸ“ˆ {col} - Top 10 (Train):")
    top_10 = train[col].value_counts().head(10)
    print(top_10)

    # testã§ã®å‡ºç¾å›æ•°
    test_counts = test[col].value_counts()

    print(f"\n   åŒã˜ã‚«ãƒ†ã‚´ãƒªã®Testå‡ºç¾å›æ•°:")
    for cat in top_10.index:
        test_count = test_counts.get(cat, 0)
        train_count = top_10[cat]
        ratio = test_count / train_count * 100 if train_count > 0 else 0
        print(f"   {cat}: Train={train_count:,}, Test={test_count:,} ({ratio:.1f}%)")

print("\n" + "=" * 80)
print("ç·åˆè©•ä¾¡")
print("=" * 80)

print("""
âœ… çµè«–:
  - å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§æ­£ã—ãã‚«ãƒ©ãƒ ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã™
  - Target Encodingã®åŠ¹æœã‚’ä¸Šè¨˜ã®çµæœã‹ã‚‰åˆ¤æ–­ã—ã¦ãã ã•ã„
  
æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:
  - Coverage (ãƒ¬ã‚³ãƒ¼ãƒ‰) ãŒ 95% ä»¥ä¸Š: ãã®ã‚«ãƒ©ãƒ ã¯éå¸¸ã«æœ‰åŠ¹
  - Coverage (ãƒ¬ã‚³ãƒ¼ãƒ‰) ãŒ 80-95%: ãã®ã‚«ãƒ©ãƒ ã¯æœ‰åŠ¹ã ãŒè¦æ³¨æ„
  - Coverage (ãƒ¬ã‚³ãƒ¼ãƒ‰) ãŒ 80% æœªæº€: ä»–ã®ç‰¹å¾´é‡ã‚’æ¤œè¨
""")

print("\nâœ… åˆ†æå®Œäº†")

